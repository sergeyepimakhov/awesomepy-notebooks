{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Creating pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "\n",
    "with beam.Pipeline(options=PipelineOptions()) as p:\n",
    "  pass  # build your pipeline here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam.runners.interactive.interactive_beam as ib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Configuring pipeline options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PCollections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Reading from an external source\n",
    "\n",
    "```python\n",
    "lines = p | 'ReadMyFile' >> beam.io.ReadFromText('gs://some/inputData.txt')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Creating a PCollection from in-memory data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be, or not to be: that is the question: \n",
      "Whether 'tis nobler in the mind to suffer \n",
      "The slings and arrows of outrageous fortune, \n",
      "Or to take arms against a sea of troubles, \n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "def print_row(element):\n",
    "  print(element)\n",
    "\n",
    "with beam.Pipeline() as pipeline:\n",
    "  lines = (\n",
    "      pipeline\n",
    "      | beam.Create([\n",
    "          'To be, or not to be: that is the question: ',\n",
    "          \"Whether 'tis nobler in the mind to suffer \",\n",
    "          'The slings and arrows of outrageous fortune, ',\n",
    "          'Or to take arms against a sea of troubles, ',\n",
    "      ])\n",
    "      | 'Print result' >> beam.Map(print_row)\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Core Beam transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map (Same as ParDo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fe759a3a780>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "def print_row(element):\n",
    "  print(element)\n",
    "\n",
    "pipeline = beam.Pipeline()\n",
    "words = (\n",
    "      pipeline\n",
    "      | beam.Create([\n",
    "          'Cat',\n",
    "          'Dog',\n",
    "          'Bat',\n",
    "          'Rabbit',\n",
    "      ])\n",
    "  )\n",
    "\n",
    "# Apply a ParDo to the PCollection \"words\" to compute lengths for each word.\n",
    "word_lengths = words | beam.Map(len) | 'Print result' >> beam.Map(print_row)\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FlatMap (same as ParDo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fe7599916a0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "def print_row(element):\n",
    "  print(element)\n",
    "\n",
    "pipeline = beam.Pipeline()\n",
    "words = (\n",
    "      pipeline\n",
    "      | beam.Create([\n",
    "          'Cat',\n",
    "          'Dog',\n",
    "          'Bat',\n",
    "          'Rabbit',\n",
    "      ])\n",
    "  )\n",
    "\n",
    "# Apply a ParDo to the PCollection \"words\" to compute lengths for each word.\n",
    "word_lengths = words | beam.FlatMap(lambda word: [len(word)]) | 'Print result' >> beam.Map(print_row)\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ParDo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fe759a6e5c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "def print_row(element):\n",
    "  print(element)\n",
    "\n",
    "pipeline = beam.Pipeline()\n",
    "words = (\n",
    "      pipeline\n",
    "      | beam.Create([\n",
    "          'Cat',\n",
    "          'Dog',\n",
    "          'Bat',\n",
    "          'Rabbit',\n",
    "      ])\n",
    "  )\n",
    "\n",
    "\n",
    "# The DoFn to perform on each element in the input PCollection.\n",
    "class ComputeWordLengthFn(beam.DoFn):\n",
    "  def process(self, element):\n",
    "    return [len(element)]\n",
    "\n",
    "\n",
    "# Apply a ParDo to the PCollection \"words\" to compute lengths for each word.\n",
    "word_lengths = words | beam.ParDo(ComputeWordLengthFn()) | 'Print result' >> beam.Map(print_row)\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. GroupByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cat', [1, 5, 9])\n",
      "('dog', [5, 2])\n",
      "('and', [1, 2, 6])\n",
      "('jump', [3])\n",
      "('tree', [2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fe7599bba20>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "def print_row(element):\n",
    "  print(element)\n",
    "\n",
    "pipeline = beam.Pipeline()\n",
    "words = (\n",
    "      pipeline\n",
    "      | beam.Create([\n",
    "          ('cat', 1),\n",
    "          ('dog', 5),\n",
    "          ('and', 1),\n",
    "          ('jump', 3),\n",
    "          ('tree', 2),\n",
    "          ('cat', 5),\n",
    "          ('dog', 2),\n",
    "          ('and', 2),\n",
    "          ('cat', 9),\n",
    "          ('and', 6)\n",
    "      ])\n",
    "  )\n",
    "\n",
    "\n",
    "# Apply a ParDo to the PCollection \"words\" to compute lengths for each word.\n",
    "word_lengths = words | beam.GroupByKey() | 'Print result' >> beam.Map(print_row)\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.3. CoGroupByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('amy', {'emails': ['amy@example.com'], 'phones': ['111-222-3333', '333-444-5555']})\n",
      "('james', {'emails': [], 'phones': ['222-333-4444']})\n",
      "('carl', {'emails': ['carl@example.com', 'carl@email.com'], 'phones': ['444-555-6666']})\n",
      "('julia', {'emails': ['julia@example.com'], 'phones': []})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f85d7442f98>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "def print_row(element):\n",
    "  print(element)\n",
    "\n",
    "p = beam.Pipeline()\n",
    "\n",
    "emails_list = [\n",
    "    ('amy', 'amy@example.com'),\n",
    "    ('carl', 'carl@example.com'),\n",
    "    ('julia', 'julia@example.com'),\n",
    "    ('carl', 'carl@email.com'),\n",
    "]\n",
    "phones_list = [\n",
    "    ('amy', '111-222-3333'),\n",
    "    ('james', '222-333-4444'),\n",
    "    ('amy', '333-444-5555'),\n",
    "    ('carl', '444-555-6666'),\n",
    "]\n",
    "\n",
    "emails = p | 'CreateEmails' >> beam.Create(emails_list)\n",
    "phones = p | 'CreatePhones' >> beam.Create(phones_list)\n",
    "\n",
    "results = ({'emails': emails, 'phones': phones} | beam.CoGroupByKey()) | 'Print result' >> beam.Map(print_row)\n",
    "\n",
    "\n",
    "p.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.4. Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f85d7b44780>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "def print_row(element):\n",
    "  print(element)\n",
    "\n",
    "pipeline = beam.Pipeline()\n",
    "pc = (\n",
    "      pipeline\n",
    "      | beam.Create([1, 10, 100, 1000])\n",
    "  )\n",
    "\n",
    "\n",
    "result_sum = pc | beam.CombineGlobally(sum) | 'Print result' >> beam.Map(print_row)\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f85d7e9b198>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "def print_row(element):\n",
    "  print(element)\n",
    "\n",
    "def bounded_sum(values, bound=500):\n",
    "  return min(sum(values), bound)\n",
    "\n",
    "pipeline = beam.Pipeline()\n",
    "pc = (\n",
    "      pipeline\n",
    "      | beam.Create([1, 10, 100, 1000])\n",
    "  )\n",
    "\n",
    "\n",
    "# 500\n",
    "small_sum = (pc \n",
    "             | 'Small Sum' >> beam.CombineGlobally(bounded_sum) \n",
    "             | 'Print Small Sum' >> beam.Map(print_row))\n",
    "\n",
    "# 1111\n",
    "large_sum = (pc \n",
    "             | 'Large Sum' >> beam.CombineGlobally(bounded_sum, bound=5000)  \n",
    "             | 'Print Large Sum' >> beam.Map(print_row))\n",
    "\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277.75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f85d7f8a278>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "def print_row(element):\n",
    "  print(element)\n",
    "\n",
    "# UDF\n",
    "class AverageFn(beam.CombineFn):\n",
    "  def create_accumulator(self):\n",
    "    return (0.0, 0)\n",
    "\n",
    "  def add_input(self, sum_count, input):\n",
    "    (sum, count) = sum_count\n",
    "    return sum + input, count + 1\n",
    "\n",
    "  def merge_accumulators(self, accumulators):\n",
    "    sums, counts = zip(*accumulators)\n",
    "    return sum(sums), sum(counts)\n",
    "\n",
    "  def extract_output(self, sum_count):\n",
    "    (sum, count) = sum_count\n",
    "    return sum / count if count else float('NaN')\n",
    "\n",
    "\n",
    "pipeline = beam.Pipeline()\n",
    "pc = (\n",
    "      pipeline\n",
    "      | beam.Create([1, 10, 100, 1000])\n",
    "  )\n",
    "\n",
    "\n",
    "res = (pc \n",
    "       | beam.CombineGlobally(AverageFn()) \n",
    "       | 'Print result' >> beam.Map(print_row))\n",
    "\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CombinePerKey\n",
    "\n",
    "https://beam.apache.org/documentation/transforms/python/aggregation/combineperkey/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "We use the function `sum` which takes an `iterable` of numbers and adds them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('🥕', 5)\n",
      "('🍆', 1)\n",
      "('🍅', 12)\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as pipeline:\n",
    "  total = (\n",
    "      pipeline\n",
    "      | 'Create plant counts' >> beam.Create([\n",
    "          ('🥕', 3),\n",
    "          ('🥕', 2),\n",
    "          ('🍆', 1),\n",
    "          ('🍅', 4),\n",
    "          ('🍅', 5),\n",
    "          ('🍅', 3),\n",
    "      ])\n",
    "      | 'Sum' >> beam.CombinePerKey(sum)\n",
    "      | beam.Map(print))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "We define a function saturated_sum which takes an iterable of numbers and adds them together, up to a predefined maximum number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('🥕', 5)\n",
      "('🍆', 1)\n",
      "('🍅', 8)\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "def saturated_sum(values):\n",
    "  max_value = 8\n",
    "  return min(sum(values), max_value)\n",
    "\n",
    "with beam.Pipeline() as pipeline:\n",
    "  saturated_total = (\n",
    "      pipeline\n",
    "      | 'Create plant counts' >> beam.Create([\n",
    "          ('🥕', 3),\n",
    "          ('🥕', 2),\n",
    "          ('🍆', 1),\n",
    "          ('🍅', 4),\n",
    "          ('🍅', 5),\n",
    "          ('🍅', 3),\n",
    "      ])\n",
    "      | 'Saturated sum' >> beam.CombinePerKey(saturated_sum)\n",
    "      | beam.Map(print))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
